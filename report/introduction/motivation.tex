\section{Motivation}

\subsection{Historical Perspective}

Ever since the birth of computers, the world has seen an ever-increasing demand
for computing power. Computers have revolutionized our lives and become
fundamental for our society to function. They have made it possible for
researchers to do simulations in great detail, helped the government to
streamline operations in health and economics and made banking systems more
flexible. The Internet, made possible by computers, has had a massive impact on
how we live our lives; anyone with an Internet connection can exchange
information and communicate across land borders. Today, personal computers have
become ubiquitous and found uses ranging from home entertainment systems to
portable tablet computers. As applications in all these segments becomes richer,
they demand even better performance. Home users require higher frame rates on
their multimedia applications, researchers wants more accurate simulations in
their experiments and the government will put better use to its resources by
information processing.

To meet the increasing demand for performance throughout the 80's and 90's,
researchers came up with ways to increase the clock frequency. By shortening the
critical path in the CPU and exploiting instruction level parallelism, they were
able to double single-threaded performance approximately every 18th month. The
tremendous growth in performance is depicted in \autoref{fig:moore}.

\begin{figure}
\includegraphics[width=\textwidth]{analyze-spec-benchmarks/int_graph.png}
\caption{Single-threaded performance relative to the SUN Ultra Enterprise 2,
recreated from \cite{preshing}.}
\label{fig:moore}
\end{figure}

The tradeoff, however, was an increased amount of complex logic added complexity
to the processor core. Greater complexity required a greater amount of
transistors which must fit on the same die, made possible by the reduction of
transistor size. For a long time, new process technologies allowed for smaller
and less energy consuming transistors, but as we approached the end of Dennard
scaling \cite{dennard}, the amount of logic required to accomodate speedups
could not fit on the die due to thermal constraints. Heat generation on-chip
became overwhelming and one could not simply increase the frequency or add
extra logic to gain additional performance.


\subsection{Problems of the New World}

Today's hardware designers are facing really hard problems. They must continue
to meet the market demand with respect to performance, while keeping the energy
consumption down. Energy consumption directly translates into heat generated
on-chip and is currently the limiting factor of processor design. Dealing with
this requires hardware designers to emphasize energy efficiency over pure
performance during the design phase; we are now in an era where a processor's
performance per Watt is more important than performance itself.

Heat is not the the only motivation factor to keep energy consumption down.
Processors targeting laptops, cellphones and other mobile devices has always
been energy-constrained due to their use of batteries. Lower energy consumption
would allow for longer battery life and/or heavier applications. Processors in
this segment trades off performance in return of increased energy efficiency.
More recently, however, mobile processors has become increasingly popular in
alternative domains too, such as supercomputing. Their low cost and good
performance per Watt ratio makes them attractive for massively parallel
problems, which is currently done on large and expensive supercomputers. These
machines have huge energy budgets and are frequently taken out of service after
just a couple of years, and replaced by new machines that offer better
performance for less power. For this reason, building datacenters from low-cost
embedded processors is believed to have a huge potential and change the
landscape of supercomputing the years to come.

Not only data centers benefit from the use of mobile processors. The SHMAC
research project at NTNU aims to build a single-ISA heterogeneous computing
platform with processing cores tailored to the application. Using the most
effective processor or hardware accelerator -- in terms of both energy
and performance -- is the key to success for such platforms.

There are great reasons to minimize a processor's energy consumption.
Performance alone is no longer the most important attribute of processors,
energy efficiency is even more important.


\subsection{Better Tools for Optimizing Energy Efficiency}

Given the advanced tools used to design hardware present these days, it is more
easy than ever to change, model and simulate performance and behaviour. With
these possibilities, tools that visualize variations in energy efficiency given
a CPU model could very useful in the design process. Some solutions supporting
this already exists; the most known ones being Wattch\cite{brooks2000wattch},
McPAT\cite{hpmcpat,li2013mcpat} and CACTI\cite{hpcacti}. The existing solutions
utilize various parameters and specialize in slightly different tasks.

NTNU have a long tradition of using M5/gem5 for simulation purposes, and it
would be most beneficial for the SHMAC project if such solutions could be
applied to an unmodified version of gem5. Wattch seems to be a good fit, but it
only works with SimpleScalar\cite{wattchanalysis}. McPAT worked with the old
M5\cite{m5mcpatparser}, which joined with GEMS to become gem5\cite{gem5hipeac},
but seems to have problems with the latest versions of
gem5\cite{mcpatgem5problems}. CACTI is a system for understanding trade-offs
between power, area and performance within memory
systems\cite{hpcacti,muralimanohar2010memory}. Both McPAT and Wattch uses models
and methods found in CACTI\cite{li2009mcpat}.

The immediate lack of a system that is easy to use and easy to set up motivates
the creation of a new tool that works on a higher level. PET is such a tool,
which is able to estimate power usage per time for a given workload on a given
architecture.  It will use an energy metric profile estimated from similar
processors together with a simulator trace log to calculate energy usage.  Using
this approach, PET will be able to detect if hardware modifications done to the
simulation level model will be beneficial in the realized hardware. PET will
also tell if a processor-implementation is more energy efficient than an other
given a specific workloads, thus it can help building workload optimized tiles
for the SHMAC project\cite{shmacwebpage}. Using the features of PET, one can
also adjust the energy metric profile and simulate power usage as if one
component was cheaper or more expensive in terms of energy. This will enable the
hardware designers to understand where optimizations are most beneficial.


% SHMAC, power profiles. Velg beste kjerne for gitt workload/application

% TODO: Introduce the notion of 'energy profiles', i.e. energy/time graphs

% motivation: early design stage, check architectural differences using same characteristics
% or set different weights to spesific events in the hunt for which components that needs optimization
